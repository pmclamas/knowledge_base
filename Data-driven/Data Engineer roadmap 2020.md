_This roadmap aims to give a complete picture of the modern data engineering landscape and serve as a study guide for aspiring data engineers._

_**Note to beginners:**_ beginners shouldn't feel overwhelmed by the vast number of tools and frameworks listed here. A typical engineer would master a subset of these tools throughout several years depending his/her company and career choices.

**CS Fundamentals**

-   Basic terminal usage
-   Data structures & algorithms
-   APIs
-   REST
-   Structured vs. Unstructured data
-   Serialisation
-   Linux (CLI, Vim, Shell scripting, Cronjobs)
-   Git - Version control
-   How does the computer work?
-   How does the internet work?

**Programming Languages _(learn how to write clean, extensible code. Spend some time understanding programming paradigms and best practices)_**

-   Python
-   Java
-   Rust

**Testing**

-   Unit testing
-   Integration testing
-   Functional testing

**Database fundamentals** _**(Make sure you know SQL very well. Understand the Entity-Relationship (ER) model and normalisation. Learn how to design databases and model data. Understand scaling patterns)**_

-   SQL
-   Normalisation
-   ACID transactions
-   CAP theorem
-   OLTP vs. OLAP
-   Horizontal vs. Vertical scaling

**Relational databases**

-   MySQL
-   PostgreSQL
-   MariaDB
-   Amazon Aurora (cloud)

**Non-relational databases** _**(Understand the difference between Document, Wide column, Graph and Key-value NoSQL databases. It's recommended to master one database from each category)**_

-   Document: MongoDB; Elasticsearch; Apache CouchDB
-   Wide column: Apache Cassandra; Apache HBase
-   Graph: Neo4j
-   Key-value: Redis; DynamoDB

**Data warehouses**

-   Snowflake
-   Apache Hive
-   Amazon Redshift

**Cluster computing fundamental** _**(Most modern data processing frameworks are based on Apache Hadoop and MapReduce to some extent. Understanding these concepts can help you learn modern frameworks much quicker)**_

-   Apache Hadoop
-   HDFS
-   MapReduce
-   Managed Hadoop â†’ Amazon EMR (cloud)

**Data processing** _**(Hybrid frameworks are able to process both batch and streaming data. Batch data processing is often done by analytical data warehouse applications)**_

-   Batch: Apache Pig; Apache Arrow
-   Hybrid: Apache Spark; Apache Beam; Apache Flink
-   Streaming: Apache Kafka; Apache Storm; Amazon Kinesis (cloud)

**Messaging**

-   RabbitMQ
-   Apache ActiveMQ

**Workflow scheduling**

-   Apache Airflow

**Monitoring data pipelines**

-   Prometheus
-   Datadog
-   Sentry

**Networking**

-   Protocols (HTTP/HTTPS; TCP; SSH; IP; DNS)
-   Firewalls
-   VPN
-   VPC

**Infrastructure as code**

-   Containers: Docker
-   Container orchestration: Kubernetes; Docker Swarm
-   Infrastructure provisioning: Terraform; AWS CouldFormation

**CI/CD**

-   GitHub Actions
-   Jenkins

**Identity and access management**

-   Active Directory

**Data security & privacy**

-   Legal compliance
-   Encryption
-   Key management
-   Data governance & integrity

_**Data Engineers often work closely with Data Scientists, Data analysts and Machine Learning engineers. It's good to have a basic understanding of the tools they use.**_

**Visualise Data**

-   Tableau
-   Looker
-   Grafana
-   Jupyter Notebook

**Machine Learning fundamentals**

-   Terminology (supervised vs. unsupervised learning; classification vs. regression; evaluation metrics)
-   Scikit-learn
-   Tensorflow
-   Keras
-   PyTorch

**Machine Learning Ops**

-   Tensorflow Extended
-   Kubeflow
-   Amazon SageMaker